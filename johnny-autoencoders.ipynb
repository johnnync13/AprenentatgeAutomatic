{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pickle.load( open( \"/kaggle/input/mlub-unsupervised-learning/X_train.p\", \"rb\" ) )\ny = pickle.load( open( \"/kaggle/input/mlub-unsupervised-learning/y_train.p\", \"rb\" ) )\nX_unlabeled = pickle.load( open( \"/kaggle/input/mlub-unsupervised-learning/X_unlabeled.p\", \"rb\" ) )\nX_test = pickle.load( open( \"/kaggle/input/mlub-unsupervised-learning/X_test.p\", \"rb\" ) )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val= train_test_split(X, y, test_size=0.05, random_state=66)\nX_unlabeled_train, X_unlabeled_val = train_test_split(X_unlabeled, test_size=0.05, random_state=66, shuffle = True)\n\nX_unlabeled_train = X_unlabeled_train.astype('float64')\nX_unlabeled_val = X_unlabeled_val.astype('float64')\nX_unlabeled_train /= 255\nX_unlabeled_val /= 255\n\nX_unlabeled = X_unlabeled.astype('float64')\nX_unlabeled /= 255\n\n# normalize data\nX_train = X_train.astype('float64')\nX_val = X_val.astype('float64')\nX_train /= 255\nX_val /= 255\nX_test = X_test.astype('float64')\nX_test /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_noise_and_clip_data(data):\n    noise = np.random.normal(loc=0.0, scale=0.1, size=data.shape)\n    data = data + noise\n    data = np.clip(data, 0., 1.)\n    return data\n\nX_unlabeled_noise_train = add_noise_and_clip_data(X_unlabeled_train)\nX_unlabeled_noise_val = add_noise_and_clip_data(X_unlabeled_val)\nX_unlabeled_noise = add_noise_and_clip_data(X_unlabeled)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n\n#it_train = train_datagen.flow(X_unlabeled_train, X_unlabeled_train,batch_size=128)\nit_train = train_datagen.flow(X_unlabeled_noise_train, X_unlabeled_noise_train,batch_size=128)\nsteps = it_train.n // 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nx, y = next(it_train)\nplt.imshow(x[0].astype('float32'));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train[0].max(), X_train[0].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model\nfrom keras.models import Model, Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import RMSprop\nfrom tensorflow.keras.layers import Flatten, Conv2D, Input, Dense, Reshape, Conv2DTranspose,\\\n   Activation, BatchNormalization, ReLU, Concatenate, Dropout, MaxPooling2D, UpSampling2D\nkeras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\ninput_img = Input(shape=(32,32,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_img = Input(shape=(32, 32, 3), name='ae_input')\ndef autoencoder(input_img):\n    x = Conv2D(32, 3, activation='relu', padding='same')(input_img) #32 x 32 x 32\n    x = BatchNormalization()(x)\n    x = Conv2D(32, 3, activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x) #16 x 16 x 32\n    x = Dropout(0.2)(x)\n    \n    x = Conv2D(64, 3, activation='relu', padding='same')(x) #16 x 16 x 64\n    x = BatchNormalization()(x)\n    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x) #8 x 8 x 64\n    x = Dropout(0.3)(x)\n    \n    x = Conv2D(128, 3, activation='relu', padding='same')(x) #32 x 32 x 32\n    x = BatchNormalization()(x)\n    x = Conv2D(128, 3, activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n    \n    x = Conv2D(32, 3, activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    encoded = x\n    \n    x = Conv2D(128, 3, activation='relu', padding='same')(x) #8 x 8 x 128\n    x = BatchNormalization()(x)\n    x = Conv2D(128, 3, activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2,2))(x)\n    \n    x = Conv2D(64, 3, activation='relu', padding='same')(x) #8 x 8 x 128\n    x = BatchNormalization()(x)\n    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2,2))(x)\n    \n    x = Conv2D(32, 3, activation='relu', padding='same')(x) #8 x 8 x 128\n    x = BatchNormalization()(x)\n    x = Conv2D(32, 3, activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x) # 32 x 32 x 3\n    return encoded,decoded\n\nencoded, decoded = autoencoder(input_img)\n\nae = Model(input_img,decoded)\n# encoder - utilizado para reducir la dimensión\nencoder = Model(input_img, encoded)\ndecoder = Model(input_img, decoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping_cb = keras.callbacks.EarlyStopping(patience=15)\nmodel_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"ae.h5\", save_best_only=True, verbose = 1)\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\ncallbacks = [early_stopping_cb,model_checkpoint_cb,reduce_lr]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ae.summary()\nencoder.summary()\ndecoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rounded_accuracy(y_true, y_pred):\n    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ae.compile(loss='mean_squared_error', optimizer = \"adam\",metrics=[rounded_accuracy,tf.keras.metrics.RootMeanSquaredError()])\nhistory_ae = ae.fit(it_train,steps_per_epoch=steps,epochs=30,verbose=1, validation_data = (X_unlabeled_noise_val,X_unlabeled_val),callbacks=callbacks)\n\n#history_ae = ae.fit(X_unlabeled_noise, X_unlabeled, batch_size = 128, validation_data=(X_unlabeled_noise, X_unlabeled), epochs = 20, callbacks=callbacks)\nae.save('ae.h5')\nae.save_weights('autoencoder_1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_unlabeled_val_noised = ae.predict(X_unlabeled_noise)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nrestored_img = ae.predict(X_unlabeled_noise)\nfor i in range(5):\n    \n    plt.imshow(X_unlabeled[i])\n    plt.gray()\n    plt.show()\n    \n    plt.imshow(X_unlabeled_noise[i])\n    plt.gray()\n    plt.show()\n    \n    plt.imshow(restored_img[i])\n    plt.gray()\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_denoised = ae.predict(X_unlabeled_noise)\nidx = 4\nplt.subplot(1,3,1)\nplt.imshow(X_unlabeled[idx])\nplt.title('original')\nplt.subplot(1,3,2)\nplt.imshow(X_unlabeled_noise[idx])\nplt.title('noisy')\nplt.subplot(1,3,3)\nplt.imshow(test_data_denoised[idx])\nplt.title('denoised')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mse(data_1, data_2):\n    return np.square(np.subtract(data_1, data_2)).mean()\nnoisy_clean_mse = mse(X_unlabeled, X_unlabeled_val_noised)\ndenoised_clean_mse = mse(X_unlabeled_noise, X_unlabeled)\n\nnoisy_clean_mse, denoised_clean_mse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef show_image(x):\n    plt.imshow(np.clip(x, 0, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history_ae.history['loss'])\nplt.plot(history_ae.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cnn(encode = None):\n    x = Flatten()(encode)\n    x = Dense(2048, activation='selu', kernel_initializer='he_uniform')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(2048, activation='selu', kernel_initializer='he_uniform')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(2048, activation='selu', kernel_initializer='he_uniform')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(128, activation='selu', kernel_initializer='he_uniform')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    out = Dense(100, activation='softmax')(x)\n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(input_img, cnn(encoded))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for l1 in model.layers[0:20]:\n    print(l1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for l1,l2 in zip(model.layers[0:20],ae.layers[0:20]):\n    l1.set_weights(l2.get_weights())\nfor layer in model.layers[0:20]:\n    layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nearly_stopping_cb = keras.callbacks.EarlyStopping(patience=15)\nmodel_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"ae.h5\", save_best_only=True, verbose = 1)\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_delta=0.0001)\ncallbacks = [model_checkpoint_cb,reduce_lr]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tanto el SGD, como el adam modificado funciona bien","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import SGD, Adam, RMSprop, Adadelta\nadam = tf.keras.optimizers.Adam(learning_rate = 0.00001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\nopt = SGD(lr=0.001, momentum=0.9)\nmodel.compile(loss=\"sparse_categorical_crossentropy\",optimizer=adam, metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\nit_train = datagen.flow(X_train, y_train, batch_size=64)\nsteps = int(X_train.shape[0] // 64)\n#history = model.fit_generator(it_train,steps_per_epoch=steps,epochs=100,verbose=1,validation_data=(X_val, y_val),callbacks=callbacks, shuffle = False)\nhistory = model.fit(X_train, y_train, batch_size=32, validation_data=(X_val, y_val),epochs=200,verbose=1,callbacks=callbacks)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\ny_pred = [np.argmax(y) for y in y_pred ]\ndf = pd.DataFrame(y_pred)\ndf.columns =['label']\ndf.index.name = 'index'\ndf.to_csv('y_output.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}