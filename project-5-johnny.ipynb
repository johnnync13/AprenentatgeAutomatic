{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/mlub-learning-to-count/train.txt',sep=' ',header=None)\n\n# take only the first 200 images\n#df_train = df_train.head(500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Estructura del dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import imageio\nfrom skimage import transform,io\nimport matplotlib.pyplot as plt\n# read images and store into a np array\n\ndata_dir = '/kaggle/input/mlub-learning-to-count/train/'\nim_size = 128\nN = df_train.shape[0]\nX = np.zeros((N, im_size,im_size))\ny = np.zeros((N))\ncont =0\n\nfor ind, item in df_train.iterrows():\n    im       = imageio.imread(data_dir + item[0])/255. \n    small_im = transform.resize(im, (im_size,im_size), mode='symmetric', preserve_range=True)\n    X[cont, :,:] = small_im\n    y[cont] = item[1]\n    cont+=1\n    \nplt.imshow(small_im,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im = imageio.imread(data_dir + item[0])\nnum = item[1]\nprint(\"Tamaño de la imagen: \" + str(im.shape))\nprint(\"Etiqueta num de personas: \" + str(num))\n\n\nplt.imshow(im)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Aumentacion de las imágenes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range = 15,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    shear_range = 0.1,\n    zoom_range = 0.1,\n    horizontal_flip = True,\n    vertical_flip = True,\n    fill_mode = \"nearest\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val= train_test_split(X, y, test_size=0.33, random_state=66)\n\nX_train = X_train.reshape(X_train.shape + (1,))\nX_val = X_val.reshape(X_val.shape + (1,))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\"\"\"\nplt.plot(rfc_predict,y_val,'.')\n\nprint(np.sqrt(mean_squared_error(rfc_predict,y_val)))\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## With a Neural Network\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import Dropout, Flatten, Conv2D, MaxPool2D, Dense\n\n\nkeras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=5, padding=\"same\", activation=\"relu\", input_shape=[128, 128, 1]))\nmodel.add(Conv2D(filters=32, kernel_size=5, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=2, strides=2, padding='valid'))\n\nmodel.add(Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=2, strides=2, padding='valid'))\n\nmodel.add(Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=2, strides=2, padding='valid'))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation=\"relu\"))\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(keras.layers.Dense(1, activation=\"linear\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = keras.models.load_model('/kaggle/working/model_counts.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adam = tf.keras.optimizers.Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = True)\nmodel.compile(loss=\"mean_squared_error\", optimizer=\"Adam\",metrics=[\"mean_squared_error\",tf.keras.metrics.MeanAbsoluteError()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nearlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 75)\n\n# Guardamos el mejor modelo con menor error de validación \ncheckpointer = ModelCheckpoint(filepath = \"model_counts.hdf5\", verbose = 1, save_best_only=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', mode = 'auto', factor=0.2, verbose = 1, patience=15, min_lr=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_datagen.flow(X_train, y_train, batch_size=64),steps_per_epoch=len(X_train) // 64, \n                    epochs=500, validation_data=(X_val, y_val),\n                    verbose=1,callbacks=[earlystopping, checkpointer,reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = keras.models.load_model('/kaggle/working/model_counts.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame(history.history)[['loss','val_loss']].plot(figsize=(8, 5))\nplt.grid(True)\n#plt.gca().set_ylim(0.4, 0.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_model1 = model.predict(X_val)\n\nplt.plot(y_model1,y_val,'.')\nnp.sqrt(mean_squared_error(y_model1,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## evaluate test and generate submission\ntest_dir = '/kaggle/input/mlub-learning-to-count/test/test/'\nim_size = 128\nN = 500\nX_test = np.zeros((N, im_size,im_size))\ncont =0\n\nfor x in range(500):\n    im       = imageio.imread(test_dir + 'test_composite'+str(x).zfill(9) + '.png')/255.\n    small_im = transform.resize(im, (im_size,im_size), mode='symmetric', preserve_range=True)\n    X_test[cont, :,:] = small_im\n    cont+=1\n    \nplt.imshow(small_im)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test.reshape(X_test.shape + (1,))\n\n# create the file to make the sumbission\n\ny_test = model.predict(X_test)\ny_test = [int(x[0]) for x in y_test]\n\ndf_output = pd.DataFrame(y_test)\ndf_output.index.name = 'index'\ndf_output.columns = ['prediction']\ndf_output.to_csv('output.csv')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}